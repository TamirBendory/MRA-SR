\documentclass[english,12pt]{article}


\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\newcommand{\I}{\iota}
\newcommand{\R}{\mathbb{R}}
%\newcommand{\tB}{\tilde{B}}
\newcommand{\tB}{B_w}

\numberwithin{equation}{section}

\newtheorem{claim}{Claim}
\newtheorem{conj}{Conjecture}
\newtheorem{cor}{Corollary}
\newtheorem{prop}{Proposition}

\begin{document}

\title{Super-resolution meets multi-reference alignment}

\author{Tamir Bendory}
\date{January 2019}
\maketitle


\section{Introduction}

Discuss classical super-resolution, multi-reference alignment, bispectrum, the effect of noise and bias

\section{Model}

We assume to collect $N$ independent observations from the model 
\begin{equation} \label{eq:model}
y = PR_\theta x + \varepsilon,
\end{equation}
%so that 
%\begin{equation}
%y_i = PR_{\theta_i} x_i + \varepsilon_i, \quad i=1,\ldots,N.
%\end{equation}
where $x\in S^1$ is a signal on the circle, $R_\theta$ denotes a random, unknown rotation, and $\theta$ is distributed uniformly $\theta\sim \text{Uniform}[0,1)$. 
The noise is assumed to be normal i.i.d.\  $\varepsilon\sim\mathcal{N}(0,\sigma^2 I)$.
In this work, we mainly focus on the high noise regime in which $\sigma$ is greater than $\|x\|_2$. 
Following the rotation, the operator $P$ collects $L$ equally-spaced samples of the signal. Thus, the recorded samples of the $i$th measurement are given by 
\begin{equation}
y_i[\ell] = \left(R_{\theta_i} x\right)[\ell] + \varepsilon_i[\ell], \quad \ell=0,\ldots,L-1.
\end{equation}
Throughout, we assume that $\sigma^2$. In many applications, the variance of the noise can be estimated accurately from the samples, or is known apriori. %Specifically for~\eqref{eq:model} the variance can be estimated by

The underlying  signal  is assumed to be band-limited so it can be expanded in a finite Fourier expansion 
\begin{eqnarray} \label{eq:fourier_expansion}
x(t) = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I bt }. \quad t\in[0,1),
\end{eqnarray}
We are interested the interplay between the number of samples $L$ and the signal's band-width $B := 2\tB+1$. We denote this ratio by  $LK=B$ for some \emph{down-sampling factor} $K\in\mathbb{Z}_{>0}$.  
This model, for which we refer to as the \emph{continuous SR model}, is the main subject of this paper. 


In addition to the continuous case, we consider the \emph{discrete SR model}. 
In this model, we allow $\theta$ to rotate only on a grid over $S^1$ defined by  $$\mathcal{B}:=\left\{0,\frac{1}{B},\ldots\frac{B-1}{B}\right\}.$$
In each measurement, the signal is rotated uniformly over  $\mathcal{B}$, and then sampled on a coarser grid 
\begin{equation} \label{eq:grid_L}
\mathcal{L}_0:=\left\{0,\frac{K}{B},\frac{2K}{B},\ldots,\frac{(L-1)K}{B}\right\}.
\end{equation}

Under this model, the samples of the $i$th measurement can be then written as
\begin{equation}
y_i[\ell] = x\left(\frac{\ell K+\tau}{B}\right)=x\left(\frac{\ell}{L} + \frac{\tau}{B}\right), \quad \ell=0,\ldots L-1,
\end{equation}
for some random $\tau\in\{0,\ldots B-1\}$. 
We also note that according to~\eqref{eq:fourier_expansion},  $y$ can be expanded by a Fourier series as
\begin{eqnarray}
y_\tau[\ell] = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{eqnarray}

The discrete model can be formulate conveniently in a matrix-vector notation as  
\begin{equation} \label{eq:discrete_model}
y^d = P_BR_{\theta_\mathcal{B}} x^d + \varepsilon,
\end{equation}
where $x^d\in\mathbb{R}^{B}$ is the restriction of $x$ to $\mathcal{B}$, $R_{\theta_\mathcal{B}}$ is a circular shift (uniformly distributed) on $\mathcal{B} $and the sampling operator $P_B\in\mathbb{R}^{B\times B}$ can be thought of as a diagonal matrix, whose diagonal is composed of 1's every other $K$ entry, and zero otherwise

The main goal of this work is to analyze the conditions enabling accurate estimate of $x$ in the continuous and discrete models in high noise regimes. As we show, accurate recovery depends on the relations between two pairs of parameters: the number of measurements as a function of the noise level, and the number of required samples as a function of the signal's band-width. Since our analysis is based on the method of moments, the required number of measurements scales asymptotically as $\sigma^{2d}$, where $d$ is the higher-order moment used~\cite{abbe2018estimation,bandeira2017estimation}. 
In this work, we focus on the third-moment---the bispectrum---and thus $N$ should be, at least, proportional to $\sigma^6$. In Section XXX we discuss the implication of using higher moments. Hence, we now proceed to analyze the how many samples are required for a given band-width. 


\section{Analysis of discrete super-resolution}

We begin by analyzing the discrete setting~\eqref{eq:discrete_model}. For the analysis, we split the discrete signal $x_B\in\mathbb{R}^B$ into $K$ signals, denoted by $x_0,\ldots,x_{K-1}\in\mathbb{R}^L$ as follows:
\begin{eqnarray}
x_i[\ell] = x^d[K\ell+i], \quad \ell=0,\ldots L-1. 
\end{eqnarray}
Each one of the signals corresponds to some random rotation of $x$ on the grid  $$\mathcal{L}_i:=\left\{i,\frac{K+i}{B},\frac{2K+i}{B},\ldots,\frac{(L-1)K+i}{B}\right\}.$$
Using this notation, one can reformulate the model as 
\begin{equation} \label{eq:heter_mra}
y^d =  R_{\theta_{\mathcal{L}_0}} x_{v} + \varepsilon,
\end{equation}
where $v$ distributed uniformly over $\{0,\ldots,K-1\}$ and $\mathcal{L}_0$ is defined in~\eqref{eq:grid_L}. 

The model~\eqref{eq:heter_mra} has been studied in the literature under the name \emph{heterogeneous multi-reference alignment}~\cite{perry2017sample,bandeira2017estimation,boumal2018heterogeneous}. In particular, in the limit of $N\to\infty$ it is straight-forward to show that 
\begin{align} \label{eq:mix_invariants}
\mu_{y^d} &= \frac{1}{K}\sum_{i=1}^K \mu_{x_i}, \nonumber\\
P_{y^d} &= \frac{1}{K}\sum_{i=1}^K P_{x_i} + \sigma^2L\mathbf{1}, \\
B_{y^d} &= \frac{1}{K}\sum_{i=1}^K (B_{x_i} +\mu_{x_i}\sigma^2L^2 A ), \nonumber
\end{align}
where $\mathbf{1}\in\mathbb{R}^L$ is a vector of ones, and $A\in\mathbb{R}^{L\times L}$ is a zero matrix except $A[0,0]=3$ and $A[i,0]=A[0,i]=A[i,i]=1$ for $i=1,\ldots,L-1$.
Given $\sigma^2$, one can debias the invariant estimations and the problem reduces to the question of demixing.

Recovering the set of $K$ signals from the invariants~\eqref{eq:mix_invariants} was studied~\cite{bandeira2017estimation}. In this work, it was shown that $K$ generic signals can be recovered from~\eqref{eq:mix_invariants}, up to permutation and cyclic shifts, as long as 
\begin{equation} \label{eq:Pl}
\mathcal{P}(L) := \frac{L+3+\left\lfloor L/2\right\rfloor +  \left\lceil (L-1)(L-2)/6\right\rceil}{L+1} > K.
\end{equation}
Since $\mathcal{P}(L) \approx L/6$, we conclude that the bound on the down-sampling factor scales as $\sqrt{B/6}$.
This bound was proved (by computational tools) for $K\leq 15$, and was conjectured to hold true for any $K$~\cite{bandeira2017estimation}.

Therefore, we conclude the following result:
\begin{prop} \label{prop1}
Consider the  discrete periodic model~\eqref{eq:discrete_model} when $N\to\infty$. 
For $K\leq 15$ and for $\mathcal{P}(B/K)>K$, one can identify the signals 
\begin{equation} \label{eq:set_signals}
R_{\theta_0}x_{\pi(0)}, \ldots,R_{\theta_{K-1}}x_{\pi(K-1)},
\end{equation}
for some arbitrary cyclic shifts $R_{\theta_i}$ for $i=0,\ldots,L-1$, and a permutation $\pi$.
If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$.
\end{prop}	

It is important to note that Proposition~\eqref{prop1} is theoretical in the sense that it is not clear whether the bound~\eqref{eq:Pl} can be achieved computationally.  
This question was studied empirically in~\cite{boumal2018heterogeneous}. Numerical evidences suggest that the maximal number of signals that can recovered, up cyclic shifts and permutation, from~\eqref{eq:mix_bispectra} is $\sqrt{L}$. If this is true, then the number of signals that can be computationally 
demixed is $K\leq \sqrt{L}$, or, $K\sim B^{1/3}$. 

Proposition~\ref{prop1} suggests that all entries of the underlying signal can be recovered in the regime of~\eqref{eq:Pl}. However, there is a combinatorial number of different ways to order $x_1,\ldots,x_K$ 

\begin{conj} \label{conj1}
	Under the discrete-periodic signal, one can sub-sample by a factor of  	$K\leq \sqrt{B/6}$ and retrieve  $x$ on the grid $\mathcal{B}$, up to shift, under some smoothing condition. \textbf{We should prove this conjecture.}
\end{conj}	

Now, let us  compute the bispectrum explicitly. The third-order autocorrelation is given by (by averaging over all shifts $\ell\in\mathcal{L}$, and all rotations $\tau\in\mathcal{B}$)
\begin{equation}
\begin{split}
M_3[n_1,n_2] &= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y_\tau[\ell] y_\tau[\ell-n_1] y_\tau[\ell-n_2]\\ 
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} x\left(\frac{\ell}{L} + \frac{\tau}{B}\right) x\left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right)
x\left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right)\\
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }\right). 
\end{split}
\end{equation}
By changing the order of the summations, and noting that 
\begin{equation} \label{eq:sum}
\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I\tau (b_1+b_2+b_3)/B} = \delta_{b_1+b_2+b_3\bmod B},
\end{equation}
we get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] = 
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (b_1n_1 + b_2n_2)/L}.
\end{split}
\end{equation}
This expression can be understood in the Fourier domain by taking the $L\times L$ points DFT: 
\begin{equation} \label{eq:mix_bispectra}
\begin{split}
\hat{M_3}[q_1,q_2] &= \sum_{n_1=0}^{L-1} \sum_{n_2=0}^{L-1}
M_3[n_1,n_2]e^{-2\pi\I(n_1q_1+n_2q_2)/L} \\ &=  
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (n_1(b_1+q_1) + n_2(b_2+q_2))} \\ & = \sum_{s=0}^{K-1} \sum_{t=0}^{K-1} \hat{x}[(q_1 + tL)\bmod L] \hat{x}[(q_2 + sL)\bmod L]\hat{x}[(-q_1-q_2 - (s+t)L)\bmod L].
\end{split}
\end{equation}
\begin{cor}
	By Claim~\ref{claim1}, a mix of bispectra of the form~\eqref{eq:mix_bispectra} can be decomposed to $K$ bispectra up to permutation as long as $K\sim\sqrt{B}$. If Conjecture~\ref{conj1} is true, then it determines $x$ uniquely under some smoothness prior.  
\end{cor}

\section{Finer discretization and removing the periodicity in Fourier}

Now, we want to examine what happens when we replace $\mathcal{B}$ with a finer grid by some integer $p\geq 1$, while fixing the sampling grid $\mathcal{L}_0$. 
In this case, we can write  the third-order autocorrelation and get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] 
&= \frac{1}{LBp}\sum_{\tau=0}^{pB-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{pB}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{pB}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{pB}\right) }\right). 
\end{split}
\end{equation}
Similarly to~\eqref{eq:mix_bispectra}, we have
\begin{equation} \label{eq:sum2}
\frac{1}{pB}\sum_{\tau=0}^{pB-1}e^{2\pi\I\tau (b_1+b_2+b_3)/pB} = \delta_{b_1+b_2+b_3\bmod pB},
\end{equation}
and hence we get the constraint $$b_3=(-b_1-b_2)\bmod pB=-b_1-b_2,$$
where the last equality follows from the range of $b_1,b_2$.
This implies that we get the same bispectrum as in~\eqref{eq:mix_bispectra}, without the wrapped-around of the frequencies. As long as we assume that the spectrum of $x$ is $B$-periodic, then we get exactly the same expression. 
In other words, even if we let $\theta$ to rotated on a fine grid (with an arbitrary over-sampling factor $p$), then the averaged bispectra remains unchanged.
This follows the intuition that if the signal is band-limited, then the taking more and more samples does not make a difference. 

What happens if we remove the periodicity assumption in the frequency domain? In this case, the bispectrum remains as in~\eqref{eq:mix_bispectra}, however, many of its entries will be zero (for all indices $\vert b_1+b_2\vert \geq \tB$). The results from Bandiera et al. do not hold anymore in this case. Yet, we can safely conjecture that the $\sqrt{B}$ factor remains true in this case (which is, in fact, easier).  


\section{Back to the continuous setup}

By taking $p\to\infty$ we let the grid to rotate freely on the circle. Therefore, in the continuous setting we need to acquire $L\sim\sqrt{B}$ samples. Note also that indeed the expression~\eqref{eq:mix_bispectra} coincides with the expression we got in the continuous setting in a previous note.

\section{Future work}
general group actions

cryo-EM

higher moments

non-periodic signals 
%\section{Replacing the point-wise sampling by averaging}
%
%A more realistic sampling process averages over $L$  intervals of length $1/L$, rather than takes point-wise samples.  
%In this model, each measurement is given by 
%\begin{equation}
%y_\tau[\ell] = \int_{\ell/L}^{(\ell+1)/L}x\left(\eta + \frac{\tau}{B}\right)d\eta.
%\end{equation}
%The third-order autocorrelation is then given by 
%\begin{equation}
%\begin{split}
%M_3[n_1,n_2] &= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y_\tau[\ell] y_\tau[\ell-n_1] y_\tau[\ell-n_2]\\ 
%&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} \left(\int_{\ell/L}^{(\ell+1)/L}x\left(\eta_0 + \frac{\tau}{B}\right)d\eta_0\right)
%\left(\int_{(\ell-n_1)/L}^{(\ell-n_1+1)/L}x\left(\eta_1 + \frac{\tau}{B}\right)d\eta_1\right) \\ 
%&\times 
%\left(\int_{(\ell-n_2)/L}^{(\ell-n_2+1)/L}x\left(\eta_2 + \frac{\tau}{B}\right)d\eta_2\right)
%\\
%&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} 
%\left(\int_{(\ell-n_1)/L}^{(\ell-n_1+1)/L}\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\eta_1 + \frac{\tau}{B}\right) } d\eta_1\right) \\&\times 
%\left(\int_{(\ell-n_2)/L}^{(\ell-n_2+1)/L}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\eta_2 + \frac{\tau}{B}\right) } d\eta_2\right) \\&\times 
%\left(\int_{(\ell)/L}^{(\ell+1)/L}\sum_{b_0=-\tB}^{\tB}\hat{x}[b_0]e^{2\pi\I b_0 \left(\eta_0 + \frac{\tau}{B}\right) } d\eta_0\right).
%\end{split}
%\end{equation}
%By replacing order of sums and integrals, and using~\eqref{eq:sum} it reduces to 
%\begin{equation}
%\begin{split}
%M_3[n_1,n_2] 
%&= \frac{1}{L}\sum_{\ell=0}^{L-1}\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB} \hat{x}[b_1]\hat{x}[b_2]\hat{x}[-b_1-b_2] \\
%&\times \int_{(\ell-n_1)/L}^{(\ell-n_1+1)/L}
%\int_{(\ell-n_2)/L}^{(\ell-n_2+1)/L}
%\int_{\ell/L}^{(\ell+1)/L}
%e^{-2\pi\I b_1(\eta_1-\eta_0) } 
%e^{-2\pi\I b_2(\eta_2-\eta_0) }
% d\eta_1  d\eta_2 d\eta_0.
%\end{split}
%\end{equation}
%Now, by changing variables $\tilde \eta_1=\eta_1-\eta_0$, and $\tilde \eta_2=\eta_2-\eta_0$ we note that the ranges of the new variables are simply $[n_1/L,(n_1+1)/L)$ and $[n_2/L,(n_2+1)/L)$, respectively. 
%Thus, 
%\begin{equation}
%\begin{split}
%M_3[n_1,n_2] 
%&= \sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB} \hat{x}[b_1]\hat{x}[b_2]\hat{x}[-b_1-b_2]
%f(n_1;b_1)f(n_2;b_2)
%\end{split}
%\end{equation}
%where $f(n_1;b_1):=\int_{n/L}^{(n+1)/L}e^{-2\pi\I b\eta}d\eta.$

\bibliographystyle{plain}
\bibliography{ref}

\end{document}

