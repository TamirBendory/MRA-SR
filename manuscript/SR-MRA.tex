\documentclass[english,12pt]{article}


\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\newcommand{\I}{\iota}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
%\newcommand{\tB}{\tilde{B}}
\newcommand{\tB}{B_w}
\newcommand{\hx}{\hat{x}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\SR}{super-resolution }

\usepackage{color}
\newcommand{\TODO}[1]{{\color{red}{[#1]}}}


\newtheorem{thm}{Theorem}
\numberwithin{equation}{section}
\numberwithin{thm}{section} % important bit
\newtheorem{claim}[thm]{Claim}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}


\begin{document}

\title{Super-resolution meets multi-reference alignment}

\author{Tamir Bendory}
\date{January 2019}
\maketitle


\section{Introduction}

Discuss classical super-resolution, multi-reference alignment, bispectrum, the effect of noise and bias

\section{Model}

We first describe the  \emph{continuous \SR model}, which is the main subject of this paper.  In this model,
we assume to collect $N$ independent observations from the model 
\begin{equation} \label{eq:model}
y = PR_\theta x + \varepsilon,
\end{equation}
where $x\in S^1$ is a signal on the circle, $R_\theta$ denotes a random, unknown rotation, and $\theta$ is distributed uniformly $\theta\sim \text{Uniform}[0,1)$. 
The noise term is composed of  i.i.d.\  Gaussian entries  $\varepsilon\sim\mathcal{N}(0,\sigma^2 I)$, where $\sigma^2$ is assumed to be known.
In this work, we mainly focus on the high noise regime in which $\sigma$ is greater than $\|x\|_2$. 
Following the rotation, the operator $P$ collects $L$ equally-spaced samples of the signal. Thus, the recorded samples of the $i$th measurement are given by 
\begin{equation} \label{eq:continuous_measurements}
y_i[\ell] = \left(R_{\theta_i} x\right)[\ell] + \varepsilon_i[\ell] =  x[\ell/L+\theta_i] + \varepsilon_i[\ell], \quad \ell=0,\ldots,L-1.
\end{equation}

Without any assumption on the structure of the signal, one cannot hope to recover it from finite samples. In this work we suppose that 
the underlying  signal  is bandlimited. Therefore, it can be  be expanded as 
\begin{eqnarray} \label{eq:fourier_expansion}
x(t) = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I bt }, \quad t\in[0,1).
\end{eqnarray}
Finite bandlimit (frequently called, finite bandwidth) is a standard assumption is many data processing applications, and in particular in structural biology \TODO{REF}. 

The classical sampling theory, usually called Shannon-Nyquist sampling theorem, states that sampling rate of the signal should be at least twice its bandwidth~\cite{shannon1949communication} (for a recent comprehensive survey of modern sampling theory; see~\cite{eldar2015sampling}) \TODO{This might be in the introduction}. 
We are interested the interplay between the number of samples $L$ and  $B := 2\tB+1$. We denote this ratio by  $LK=B$ for some \emph{\SR factor} $K\in\mathbb{Z}_{>0}$.  


In addition to the continuous case, we consider the \emph{discrete \SR model}. Let us denote by $\T_T\subset S^1$ the equally-spaced grid 
\begin{equation} \label{eq:grid}
\mathcal{T}:=\left\{0,\frac{1}{T},\ldots\frac{T-1}{T}\right\}.
\end{equation}
In the discrete mode we study the case where $\theta$ is rotated on $\T_B$ and then sampled on $\T_{B/K}=\T_{L}$.
Under this model, the samples of the $i$th measurement can be  written as
\begin{equation}
y_i[\ell] = x\left(\frac{\ell K+\tau}{B}\right)=x\left(\frac{\ell}{L} + \frac{\tau}{B}\right), \quad \ell=0,\ldots L-1,
\end{equation}
for some random $\tau\in\{0,\ldots B-1\}$. 
In this case, $y$ can be expanded by a Fourier series as
\begin{eqnarray}
y_\tau[\ell] = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{eqnarray}

The discrete model can be formulated conveniently in a matrix-vector notation as  
\begin{equation} \label{eq:discrete_model}
y^d = P_BR_{\theta_\mathcal{B}} x^d + \varepsilon,
\end{equation}
where $x^d\in\mathbb{R}^{B}$ is the restriction of $x$ to $\T_B$, $R_{\theta_B}$ is a circular shift (uniformly distributed) over  $\T_B$ and the sampling operator $P_B\in\mathbb{R}^{B\times B}$ is a diagonal matrix, whose diagonal is composed of 1's every other $K$ entry, and zero otherwise

The main goal of this work is to analyze the conditions enabling accurate estimate of $x$ in the continuous and discrete models in high noise regimes. As we show, accurate recovery depends on to ratios: the number of measurements as a function of the noise level, and the number of required samples as a function of the signal's bandwidth. Since our analysis is based on the method of moments, the required number of measurements scales asymptotically as $\sigma^{2d}$, where $d$ is the higher-order moment used~\cite{abbe2018estimation,bandeira2017estimation}. 
In this degree we use the lowest-order moment possible for \SR---the bispectrum. Lower order moments do not suffice to determine a signal uniquely, a fortiori for \SR. Using the bispectrum requires the number of measurements $N$ to scale, at least, as $\sigma^6$. 
As discussed in Section~\ref{sec:future_work}, if more measurements are available, one use higher moments to resolve even higher frequencies. 
\TODO{I am using moments/invariants interchangeably}

\section{Analysis}

\subsection{The discrete model}

We begin by analyzing the discrete setting~\eqref{eq:discrete_model}. For the analysis, we split the discrete signal $x_B\in\mathbb{R}^B$ into $K$ signals, denoted by $x_0,\ldots,x_{K-1}\in\mathbb{R}^L$ as follows:
\begin{eqnarray} \label{eq:sub_signals}
x_i[\ell] = x^d[K\ell+i], \quad \ell=0,\ldots L-1. 
\end{eqnarray}
Each one of the signals corresponds to some random rotation of $x$ on the grid  $$\mathcal{L}_i:=\left\{i,\frac{K+i}{B},\frac{2K+i}{B},\ldots,\frac{(L-1)K+i}{B}\right\}.$$
Using this notation, one can reformulate the model as 
\begin{equation} \label{eq:heter_mra}
y^d =  R_{\theta_{\mathcal{L}_0}} x_{v} + \varepsilon,
\end{equation}
where $v$ distributed uniformly over $\{0,\ldots,K-1\}$ and $\mathcal{L}_0$ is defined in~\eqref{eq:grid_L}. 

The model~\eqref{eq:heter_mra} has been studied in the literature under the name \emph{heterogeneous multi-reference alignment}~\cite{perry2017sample,bandeira2017estimation,boumal2018heterogeneous}. In particular, in the limit of $N\to\infty$ it is straight-forward to show that 
\begin{align} \label{eq:mix_invariants}
\mu_{y^d} &= \frac{1}{K}\sum_{i=1}^K \mu_{x_i}, \nonumber\\
P_{y^d} &= \frac{1}{K}\sum_{i=1}^K P_{x_i} + \sigma^2L\mathbf{1}, \\
B_{y^d} &= \frac{1}{K}\sum_{i=1}^K (B_{x_i} +\mu_{x_i}\sigma^2L^2 A ), \nonumber
\end{align}
where $\mathbf{1}\in\mathbb{R}^L$ is a vector of ones, and $A\in\mathbb{R}^{L\times L}$ is a zero matrix except $A[0,0]=3$ and $A[i,0]=A[0,i]=A[i,i]=1$ for $i=1,\ldots,L-1$.
Given $\sigma^2$, one can debias the invariant estimations and the problem reduces to the question of demixing.

Recovering the set of $K$ signals from the invariants~\eqref{eq:mix_invariants} was studied~\cite{bandeira2017estimation}. In this work, it was shown that $K$ generic signals can be recovered from~\eqref{eq:mix_invariants}, up to permutation and cyclic shifts, as long as $K<\mathcal{P}(L)$ where
\begin{equation} \label{eq:Pl}
\mathcal{P}(L) := \frac{L+3+\left\lfloor L/2\right\rfloor +  \left\lceil (L-1)(L-2)/6\right\rceil}{L+1}.
\end{equation}
For $K\geq 5$, it suffices to require $K\leq \frac{L+5}{6}$. 
Since $\mathcal{P}(L) \approx L/6$, we conclude that the bound on the down-sampling factor scales as $\sqrt{B/6}$.
This bound was proved (by computational tools) for $K\leq 15$, and was conjectured to hold true for any $K$~\cite{bandeira2017estimation}.

Therefore, we conclude the following result:
\begin{prop} \label{prop1}
Consider the  discrete periodic model~\eqref{eq:discrete_model} when $N\to\infty$. 
For $K\leq 15$ and for $\mathcal{P}(B/K)>K$, one can identify the signals 
\begin{equation} \label{eq:set_signals}
R_{\theta_0}x_{\pi(0)}, \ldots,R_{\theta_{K-1}}x_{\pi(K-1)},
\end{equation}
for some arbitrary cyclic shifts $R_{\theta_i}$ for $i=0,\ldots,L-1$, and a permutation $\pi$.
If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$.
\end{prop}	

It is important to note that Proposition~\eqref{prop1} is theoretical in the sense that it is not clear whether the bound~\eqref{eq:Pl} can be achieved computationally.  
This question was studied empirically in~\cite{boumal2018heterogeneous}. Numerical evidences suggest that the maximal number of signals that can recovered, up cyclic shifts and permutation, from~\eqref{eq:mix_bispectra} is $\sqrt{L}$. 
Strong theoretical support was provided in~\cite{weinthesis}. In particular,  it was proven that $K$ signals whose entries i.i.d.\ Gaussians can be recovered with high probability from their mixed bispectrum as long as $k\leq \sqrt{L}/\text{polylog}(L)$.
In this case,the number of signals that can be computationally 
demixed scales as $K\leq \sqrt{L}$, or, $K\sim B^{1/3}$ (up to log factors).  



Proposition~\ref{prop1} suggests that all entries of the underlying signal can be recovered in the regime of~\eqref{eq:Pl}. However, there are $(L^K)\cdot K!$ \TODO{check this number}  different ways to order the signals $x_1,\ldots,x_K$. Hence, to guarantee unique recovery of the signal one must impose some prior on the signal, such as smoothness. In the following proposition, proved in Appendix~\ref{sec:proof_bandlimit}, we show that

\begin{prop} \label{prop:bandlimit}
If $x$ is a generic signal, then there is only one set of rotations and shift of~\eqref{eq:set_signals} which obeys $\hx[m]=x_m$ for some $m$ and $x_m$.
\end{prop}	

Our main interest is in bandlimited signals for which the spectrum vanished starting from some frequency. Proposition~\ref{prop:bandlimit} implies that there exists only one bandlimited signal that fits the first three moments, under the conditions presented in Proposition~\ref{prop1}. 
Hence, we conclude the following:

\begin{thm}
Consider the  discrete periodic model~\eqref{eq:discrete_model} when $N\to\infty$. Suppose that one entry of $\hx$ is known (e.g., $x$ is a bandlimited signal for which many of Fourier coefficients are zero). 
Then, For $K\leq 15$ and for $\mathcal{P}(B/K)>K$ (given in~\eqref{eq:Pl}), one can identify $x$ up to shift. 
If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$.
\end{thm}

\subsection{Explicit expressions of the invariants}

We are now turning our attention to explicit computation of the moments as a function of the Fourier coefficients of $x$ (the high-resolution signal). This computation will serve to move from the discrete setting to the continuous one. To differ it from the  

We start by computing the mean, which is defined as the expected mean of the measurements: 
\begin{equation}
\begin{split}
M_1 = \E\left\{ \frac{1}{L} \sum_{\ell=0}^{L-1} y^d[\ell]\right\} =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y^d[\ell] =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1}
\sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{split}
\end{equation}
Since $\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I b \tau/B}=\delta_b$, we conclude that 
\begin{equation} \label{eq:mean}
\begin{split}
M_1 = \hx[0].
\end{split}
\end{equation}
This  implies, agreeing with~\eqref{eq:mix_bispectra} that the average over all measurements is just the mean of the signal.  

We can now proceed with the second moment:
\begin{equation} \label{eq:ps}
\begin{split}
M_2[n] &= \E\left\{\frac{1}{L}\sum_{\ell=0}^{L-1} y^d[\ell]y^d[\ell-n]\right\} =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y^d[\ell]y^d[\ell-n] \\ &=  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1}
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell}{L} + \frac{\tau}{B}\right)} \right)
\left(\sum_{b_2=-\tB}^{\tB}\overline{\hx}[b_2]e^{-2\pi\I b_2 \left(\frac{\ell-n}{L} + \frac{\tau}{B}\right)} \right) \\
&=
\sum_{b=-\tB}^{\tB}\vert \hat{x}[b]\vert ^2e^{2\pi\I bn/L}.
\end{split}
\end{equation}
Taking the $L$-points DFT of $M_2$ we get 
\begin{equation}
\begin{split}
P[q] &= \sum_{n=0}^{L-1}M_2[n]e^{-2\pi\I nq/L} = \sum_{b=-\tB}^{\tB}\vert \hat{x}[b]\vert^2\sum_{n=0}^{L-1}e^{-2\pi\I n(q-b)/L}.
\end{split}
\end{equation}
The last term is not zero if and only if $b = q + pL$ for some $p\in\mathbb{Z}$.  Hence, we conclude that the observed power spectrum is a mix of power spectra:
\begin{equation}
\begin{split}
\frac{1}{L}\hat{M}_2[q] &=  \sum_{p=0}^{K-1} \vert \hat{x}[(q+PL)\bmod L]\vert^2.
\end{split}
\end{equation}

The more interesting computation is of the bispectrum.
 The third-order autocorrelation is given by 
\begin{equation} \label{eq:3rd_moments}
\begin{split}
M_3[n_1,n_2] &= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y_\tau[\ell] y_\tau[\ell-n_1] y_\tau[\ell-n_2]\\ 
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} x\left(\frac{\ell}{L} + \frac{\tau}{B}\right) x\left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right)
x\left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right)\\
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }\right). 
\end{split}
\end{equation}
By changing the order of the summations, and noting that 
\begin{equation} \label{eq:delta}
\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I\tau (b_1+b_2+b_3)/B} = \delta_{b_1+b_2+b_3\bmod B},
\end{equation}
we get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] = 
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (b_1n_1 + b_2n_2)/L}.
\end{split}
\end{equation}
This expression can be understood in the Fourier domain by taking the $L\times L$ points DFT: 
\begin{equation} \label{eq:mix_bispectra}
\begin{split}
B[q_1,q_2] &= \sum_{n_1=0}^{L-1} \sum_{n_2=0}^{L-1}
M_3[n_1,n_2]e^{-2\pi\I(n_1q_1+n_2q_2)/L} \\ &=  
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (n_1(b_1+q_1) + n_2(b_2+q_2))} \\ & = \sum_{p_1=0}^{K-1} \sum_{p_2=0}^{K-1} \hat{x}[(q_1 + p_1L)\bmod L] \hat{x}[(q_2 + p_2L)\bmod L]\hat{x}[(-q_1-q_2 - (p_1+p_2)L)\bmod L].
\end{split}
\end{equation}
\begin{cor}
	If $K\leq 15$ and $\mathcal{P}(B/K)>K$, then the set of signals~\eqref{eq:set_signals} are determined uniquely from~\eqref{eq:mean},\eqref{eq:ps} and~\eqref{eq:mix_bispectra}. 
	If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$. 
\end{cor}

\subsection{The continuous model}

Next, we examine the discrete model while letting $\theta$ to rotate on a finer sampling grid, while fixing the sampling grid $\mathcal{L}_0$ and the signal's bandwidth.  

Let $p$ denotes the over-sampling factor of the sampling grid of $\theta$. Similarly to~\eqref{eq:3rd_moments}, we can calculate  the third-order autocorrelation to be
\begin{equation}
\begin{split}
M_3[n_1,n_2] 
&= \frac{1}{LBp}\sum_{\tau=0}^{pB-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{pB}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{pB}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{pB}\right) }\right). 
\end{split}
\end{equation}
Similarly to~\eqref{eq:delta}, we have
\begin{equation} \label{eq:delta2}
\frac{1}{pB}\sum_{\tau=0}^{pB-1}e^{2\pi\I\tau (b_1+b_2+b_3)/pB} = \delta_{b_1+b_2+b_3\bmod pB},
\end{equation}
and hence we get the constraint $$b_3=(-b_1-b_2)\bmod pB=-b_1-b_2,$$
where the last equality follows from the range of $b_1,b_2$.
Hence, we directly get 
\begin{equation} \label{eq:3rd_moment_zeros}
\begin{split}
M_3[n_1,n_2] = 
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[-b_1-b_2]e^{-2\pi\I (b_1n_1 + b_2n_2)/L},
\end{split}
\end{equation}
and 
\begin{equation} \label{eq:mixed_bispectra_zeros}
\begin{split}
B[q_1,q_2] &= \sum_{n_1=0}^{L-1} \sum_{n_2=0}^{L-1}
M_3[n_1,n_2]e^{-2\pi\I(n_1q_1+n_2q_2)/L} \\ &=   \sum_{p_1=0}^{K-1} \sum_{p_2=0}^{K-1} \hat{x}[(q_1 + p_1L)\bmod L] \hat{x}[(q_2 + p_2L)\bmod L]\hat{x}[-q_1-q_2 - (p_1+p_2)L].
\end{split}
\end{equation}

This implies that we get the same bispectrum as in~\eqref{eq:mix_bispectra}, without the wrapped-around of the frequencies. 
That is, the bispectrum remains the same for any entry $\vert b_1 + b_2\vert \leq B$. For all other entries, the expression~\eqref{eq:mixed_bispectra_zeros} is zero, whereas~\eqref{eq:mix_bispectra} is generally not. 
This is true for any $p\geq 2$. 
This follows the intuition that if the signal is band-limited, then the taking more and more samples does not make a difference. \TODO{Does it?} 
In particular, it holds true for $p\to\infty$---that is, when $\theta$ is rotated continuously on the circle. In this case, the discrete model converges to the continuous model, which is the main interest of this paper. In appendix~\ref{sec:continuous_bispectrum} we derive expression~\eqref{eq:mixed_bispectra_zeros} directly in the continuum, without first considering the discrete case. 

Unfortunately, the results from~\cite{bandeira2017estimation} for bispectrum demixing assume a generic, periodic, signals. Thus, the expression of~\eqref{eq:mixed_bispectra_zeros} does not fall into this category. Yet, in many cases the aperiodic is provably easier than the periodic case since entries from other sides of the signal (e.g.,
low and high frequencies) do not mixed up. 
For instance, it is well know that a generic two-dimensional signal can be determined uniquely from its aperiodic autocorrelation but not from its periodic autocorrelation; see for example~\cite{hayes1982reconstruction}.\footnote{In practice, the mapping between the aperiodic autocorrelation and a signal might be extremely sensitive~\cite{barnett2018geometry}.}. The aperiodicity also plays a key role in other related fields, such as ultra-short pulse characterization~\cite{bendory2018signal}. 
Based on that intuition, we conjecture that the same super-resolution factor remains true for the continuous case, possibly with a different constant. 

\begin{conj}
Consider the  continuous periodic model~\eqref{eq:continuous_measurements} when $N\to\infty$, and that $x$ is a B-bandlimited signal, the  one can identify $x$ up to shift as long as $K\leq C \sqrt{B}$, where $C$ is a constant that does not depend on either $K$ or $B$.
\end{conj}

\section{An expectation-maximization algorithm for super-resolution}

Our theoretical study is based on the invariant features. Conceptually, it suggests a two stages procedure: first estimate rotated and permuated version of the signals $x_1,\ldots,x_k$ (see~\eqref{eq:sub_signals}), from their mixed bispectrum, and then order them according to some smoothness prior on the underlying signal. While efficient bispectrum demixing is possible in some regime~\cite{boumal2018heterogeneous}, this approach suffers from two drawbacks. First, even if there is a unique set of rotations and permutation which agree with the data and the smoothness prior, it is not clear how to achieve it. Second, any error in the in finding the appropriate set of rotations and permutation may result in a a completely different signal. Hence, such a procedure may be very sensitive to errors. 
As an alternative, we propose using the expectation-maximization (EM) framework described below. 

EM is a popular  framework to compute the marginalized maximum likelihood estimator (MMLE), proposed in~\cite{dempster1977maximum}. While its behavior is generally not understood, it works quite well in practice. We assume here that $\theta$ is restricted to rotate on a discrete grid $\mathcal{T}$. Given a set of $N$ measurements $y_1,\ldots,y_N$, the likelihood function for the model under consideration is proportional to $p(y_1,\ldots,y_N|x)p(x)$, where $p(x)$ is a prior on the signal. In this work, we that the signal is Gaussian with zero mean and known covariance $\Sigma$.
Hence,  a simple calculation shows that (up to a constant) the log-likelihood   then takes the form (cf.~\cite{bendory2017bispectrum,abbe2018multireference})
\begin{equation}
\log \mathcal{L}(y|x)  = -\frac{1}{2\sigma^2}\sum_{i=1}^{N}\|y_i - PR_{\theta_i}x\| - \frac{1}{2}x^T\Sigma^{-1}x.
\end{equation}
The algorithm aims to compute the MMLE by marginalizing over the the rotations  $\log \mathcal{L}(y|x)  = \sum_{\theta\in\mathcal{T}}\log \mathcal{L}(y|\theta,x)$. Computing the MMLE directly is intractable as one need to evaluate the an exponential number of combinations of rotations. The EM suggests to try to obtain the MMLE iteratively. 

The signal's estimation is usually initialized randomly. 
Each EM iteration consists of two steps.
The first, called the E-step, computes the expected value of the likelihood function  given the current estimate of the signal $x_t$ and the data $y_1,\ldots,y_N$
\begin{equation}
\begin{split}
Q(x|x_t) &= \E_{\theta|y_i,x_t}\left\{\ \log \mathcal{L}(y_1,\ldots,y_N,\theta|x_t).   \right\} \\
& = -\frac{1}{2\sigma^2}\sum_{i=1}^{N}\sum_{\tau\in\mathcal{T}}w_{i,\tau}\|y_i - PR_{\tau}x\| - \frac{1}{2}x^T\Sigma^{-1}x,
\end{split}
\end{equation} 
where 
\begin{equation} \label{eq:em_weights}
w_{i,\tau} = P[\theta_i = \tau] = \frac{e^{\frac{-1}{2\sigma^2}\|y_i-PR_\tau x_t\|^2 }}{\sum_{\tau\in\mathcal{T}}e^{\frac{-1}{2\sigma^2}\|y_i-PR_\tau x_t\|^2 }}.
\end{equation}
Then, second step is to maximize $Q$ with respect to $x$. In that case, the solution is obtained bu solving the linear system of equations
\begin{equation} \label{eq:em_linear_system}
Ax = b,
\end{equation}
where 
\begin{align}
A :=&  \Sigma^{-1} + \frac{1}{\sigma^2}\sum_{i,\tau}\omega_{i,\tau} (R_\tau^{-1}P^TPR_\tau),\\ 
b :=&   \frac{1}{\sigma^2} \sum_{i,\tau}\omega_{i,\tau}R_\tau^{-1}P^Ty_i.
\end{align}
\TODO{These expression are for general linear operator; for our specific case many steps can be implemented using fft.}
The EM is then iterate between computing the weights~\eqref{eq:em_weights} and solving the linear system~\eqref{eq:em_linear_system}.

\section{Numerical results}


\section{Future work} \label{sec:future_work}
general group actions

cryo-EM~\cite{chen2018single}.

higher moments

non-periodic signals 

	
	
\bibliographystyle{plain}
\bibliography{ref}


\appendix

\section{Proof of Proposition~\ref{prop:bandlimit}} \label{sec:proof_bandlimit}
Suppose that $x_1,\ldots,x_K\in\R^L$ are known.
The combined signal is then given by 
\begin{equation}
x = \sum_{i=1}^K T_kZR_kx_k,
\end{equation}
where $R_k$ are (unknown) cyclic shifts of the signals $x_k$, $Z$ denotes a zero-padding operator (by a factor of $K$) so that $Zx_k\in\mathbb{R}^B$, and $T_k$ shifts the zero-padded signals by $k$ entries for $k=0,\ldots, K-1$. 
For instance, for $K=3$ we have: 
\begin{equation}
Zx = (x[0],0,0,x[1],0,0,x[2],...)\in\mathbb{R}^B.
\end{equation}

The Fourier transform of a signal $u\in\mathbb{R}^{L}$ is defined by 
\begin{equation}
\hat{u}[m]=\sum_{\ell=0}^{L-1}u[\ell]e^{-2\pi\I m\ell /L}, \quad m=0,\ldots,L-1. 
\end{equation}
The Fourier transform of $Zu$ is then given by 
\begin{equation}
\widehat{(Zu)}[m] = \sum_{\ell=0}^{L-1}u[\ell]e^{-2\pi\I m\ell /(B/K)}, \quad m=0,\ldots,B-1.
\end{equation}
In other words, $\widehat{(Zu)}[m] = \hat{u}[m\bmod L]$.


The Fourier transform of $ZR_{r_k}u$ is  given by 
\begin{equation}
\widehat{(ZR_{r_k}u)}[m] = e^{-2\pi\I m r_k L} \hat{u}[m\bmod L], \quad m=0,\ldots,B-1.
\end{equation}
for 
This signal is shifted once again and we get
\begin{eqnarray} \label{eq:Fourier_structure}
\hat{x}[m] = \sum_{k=1}^K e^{-2\pi\I m( p_k+r_k K)/B} \hat{x}_k[m \bmod L]. 
\end{eqnarray}
for $m=0,\ldots,B-1$, 
where $r_k$ is a chosen randomly uniformly over $\{0,\ldots,L-1\}$, independently for each $k$, and $p_k$ represents the permutations, that is, $p_k\in\{0,\ldots K-1\}$, $p_k\neq p_\ell$ for all $k\neq \ell$ (note that we do have the freedom to fix one signal and its shift). 

Let us denote the set of rotations and permutation that satisfy the assumption  $\hx[m]=x_m$ by $\tilde{p}_k,\tilde{r}_k$. Let $E_k:=e^{-2\pi\I m( p_k+r_k K)/B}$, $\tilde{E}_k:=e^{-2\pi\I m( \tilde{p}_k+\tilde{r}_k K)/B}$ and $\hx_k:=\hat{x}_k[m \bmod L]$ for fixed $m$. Now, let us assume that there exists another $E_k$ that satisfies the constraint. In this case,
\begin{equation} \label{eq:inner_product}
x_m=\left\langle E_k,\hx_k\right\rangle = \left\langle \tilde{E}_k,\hx_k\right\rangle \quad \Rightarrow \quad\left\langle \tilde{E}_k -{E}_k,\hx_k\right\rangle =0.
\end{equation} 
For generic $x$, the orthogonal complement of $\hx_k$ is Lebesgue measure zero and therefore~\eqref{eq:inner_product} is not satisfied generically.  

\section{Derivation of the bispectrum in the continuous model} \label{sec:continuous_bispectrum}

In this appendix, we compute the bispectrum explicitly for the continuous setting. The third-order autocorrelation is given by (by averaging over all shifts $\ell\in\mathcal{L}$, and all rotations on the circle)
\begin{equation}
\begin{split}
M_3[n_1,n_2] &= \E_{\theta\sim\text{U}[0,1)}\left\{ \sum_{\ell=0}^{L-1}  y_\theta[\ell] y_\theta[\ell-n_1] y_\theta[\ell-n_2]\right\} 
\\&=\int_{0}^{1}\left(\frac{1}{L}\sum_{\ell=0}^{L-1} y_\theta[\ell] y_\theta[\ell-n_1] y_\theta[\ell-n_2]\right)d\theta\\ 
&= \frac{1}{L}\sum_{\ell=0}^{L-1}\int_{0}^{1} x\left(\frac{\ell}{L} + \theta\right) x\left(\frac{\ell-n_1}{L} + \theta\right)
x\left(\frac{\ell-n_2}{L} + \theta\right)d\theta\\
&= \frac{1}{L}\sum_{\ell=0}^{L-1}\int_{0}^{1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \theta\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \theta\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \theta\right) }\right). 
\end{split}
\end{equation}
Since $\int_{0}^{1}e^{2\pi\I\theta(b_1+b_2+b_3)}d\theta=\delta_{b_1+b_2+b_3}$, we get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] =   \sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB} \hat{x}[b_1]\hat{x}[b_2]\hat{x}[-b_1-b_2]e^{-2\pi\I (b_1n_1+b_2n_2)},
\end{split}
\end{equation}
which is exactly~\eqref{eq:3rd_moment_zeros}. Hence, taking the $L\times L$ DFT we get~\eqref{eq:mixed_bispectra_zeros}.

\end{document}

