\documentclass[english,12pt]{article}


\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\newcommand{\I}{\iota}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
%\newcommand{\tB}{\tilde{B}}
\newcommand{\tB}{B_w}
\newcommand{\hx}{\hat{x}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\SR}{super-resolution }

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


\usepackage{color}
\newcommand{\TODO}[1]{{\color{red}{[#1]}}}


\newtheorem{thm}{Theorem}
\numberwithin{equation}{section}
\numberwithin{thm}{section} % important bit
\newtheorem{claim}[thm]{Claim}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}


\begin{document}

\title{Super-resolution meets multi-reference alignment}

\author{Tamir Bendory}
\date{January 2019}
\maketitle


\section{Introduction}

Discuss classical super-resolution, multi-reference alignment, bispectrum, the effect of noise and bias
cryo-EM is a motivation~\cite{chen2018single}

\section{Model}

We first describe the  \emph{continuous \SR model}, which is the main subject of this paper.  In this model,
we assume to collect $N$ independent observations from the model 
\begin{equation} \label{eq:model}
y = PR_\theta x + \varepsilon,
\end{equation}
where $x\in S^1$ is a signal on the circle, $R_\theta$ denotes a random, unknown rotation, and $\theta$ is distributed uniformly $\theta\sim \text{Uniform}[0,1)$. 
The noise term is composed of  i.i.d.\  Gaussian entries  $\varepsilon\sim\mathcal{N}(0,\sigma^2 I)$, where $\sigma^2$ is assumed to be known.
In this work, we mainly focus on the high noise regime in which $\sigma$ is greater than $\|x\|_2$. 
Following the rotation, the operator $P$ collects $L$ equally-spaced samples of the signal. Thus, the recorded samples of the $i$th measurement are given by 
\begin{equation} \label{eq:continuous_measurements}
y_i[\ell] = \left(R_{\theta_i} x\right)[\ell] + \varepsilon_i[\ell] =  x[\ell/L+\theta_i] + \varepsilon_i[\ell], \quad \ell=0,\ldots,L-1.
\end{equation}

Without any assumption on the structure of the signal, one cannot hope to recover it from finite samples. In this work we suppose that 
the underlying  signal  is bandlimited. Therefore, it can be  be expanded as 
\begin{eqnarray} \label{eq:fourier_expansion}
x(t) = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I bt }, \quad t\in[0,1).
\end{eqnarray}
Finite bandlimit (frequently called, finite bandwidth) is a standard assumption is many data processing applications, and in particular in structural biology \TODO{REF}. 

The classical sampling theory, usually called Shannon-Nyquist sampling theorem, states that sampling rate of the signal should be at least twice its bandwidth~\cite{shannon1949communication} (for a recent comprehensive survey of modern sampling theory; see~\cite{eldar2015sampling}) \TODO{This might be in the introduction}. 
We are interested the interplay between the number of samples $L$ and  $B := 2\tB+1$. We denote this ratio by  $LK=B$ for some \emph{\SR factor} $K\in\mathbb{Z}_{>0}$.  


In addition to the continuous case, we consider the \emph{discrete \SR model}. Let us denote by $\T_T\subset S^1$ the equally-spaced grid 
\begin{equation} \label{eq:grid}
\mathcal{T}:=\left\{0,\frac{1}{T},\ldots\frac{T-1}{T}\right\}.
\end{equation}
In the discrete mode we study the case where $\theta$ is rotated on $\T_B$ and then sampled on $\T_{B/K}=\T_{L}$.
Under this model, the samples of the $i$th measurement can be  written as
\begin{equation}
y_i[\ell] = x\left(\frac{\ell K+\tau}{B}\right)=x\left(\frac{\ell}{L} + \frac{\tau}{B}\right), \quad \ell=0,\ldots L-1,
\end{equation}
for some random $\tau\in\{0,\ldots B-1\}$. 
In this case, $y$ can be expanded by a Fourier series as
\begin{eqnarray}
y_\tau[\ell] = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{eqnarray}

The discrete model can be formulated conveniently in a matrix-vector notation as  
\begin{equation} \label{eq:discrete_model}
y^d = P_BR_{\theta_B} x^d + \varepsilon,
\end{equation}
where $x^d\in\mathbb{R}^{B}$ is the restriction of $x$ to $\T_B$, $R_{\theta_B}$ is a circular shift (uniformly distributed) over  $\T_B$ and the sampling operator $P_B\in\mathbb{R}^{B\times B}$ is a diagonal matrix, whose diagonal is composed of 1's every other $K$ entry, and zero otherwise

The main goal of this work is to analyze the conditions enabling accurate estimate of $x$ in the continuous and discrete models in high noise regimes. As we show, accurate recovery depends on to ratios: the number of measurements as a function of the noise level, and the number of required samples as a function of the signal's bandwidth. Since our analysis is based on the method of moments, the required number of measurements scales asymptotically as $\sigma^{2d}$, where $d$ is the higher-order moment used~\cite{abbe2018estimation,bandeira2017estimation}. 
In this degree we use the lowest-order moment possible for \SR---the bispectrum. Lower order moments do not suffice to determine a signal uniquely, a fortiori for \SR. Using the bispectrum requires the number of measurements $N$ to scale, at least, as $\sigma^6$. 
As discussed in Section~\ref{sec:future_work}, if more measurements are available, one use higher moments to resolve even higher frequencies. 
\TODO{I am using moments/invariants interchangeably}

\section{Analysis}

We start by rigorous analysis of the discrete model in Section~\ref{sec:discrete_analysis} and deriving Theorem~\ref{thm:discrete}. Then, several intermediate calculations in Section~\ref{sec:expressions}  lead to the analysis of the continuous case and Conjecture~\ref{conj:continuous}.

\subsection{The discrete model} \label{sec:discrete_analysis}

We begin by analyzing the discrete setting~\eqref{eq:discrete_model}. 
For $i=,\ldots,K-1$, let us define 
\begin{equation} \label{eq:sub_signals}
x_i[\ell] = x[K\ell + i], \quad \ell=0,\ldots,L-1.
\end{equation}
Using~\eqref{eq:sub_signals}, one can think about each measurement in the discrete model 
as a two stages procedure. First, one of the $K$ signals~\eqref{eq:sub_signals} is chosen uniformly at random. Then, a random cyclic shift on the grid $\T_L$ is acted upon the chosen signal.
Therefore, the model can be reformulate  as 
\begin{equation} \label{eq:heter_mra}
y^d =  R_{\theta_{L}} x_{v} + \varepsilon,
\end{equation}
where $v$ distributed uniformly over $\{0,\ldots,K-1\}$ and $R_{\theta_L}$ is a circular shift on the grid $\T_L$. 

The model~\eqref{eq:heter_mra} has been studied in the literature under the name \emph{heterogeneous multi-reference alignment}and analyzed using the method of moments~\cite{perry2017sample,bandeira2017estimation,boumal2018heterogeneous}. Under the assumption of uniform distribution of cyclic shifts, the moments are completely equivalent to polynomials that are invariant under cyclic shifts. In particular, we make use of the first three invariants, the mean $\mu$, the power spectrum $P$ and the bispectrum $B$. These invariants can be described readily in the Fourier transform. In particular, for a signal $z\R^p$, we define
\begin{align}
&\mu_z = \hat{z}[0], \nonumber \\
&P_z[q] = \vert \hat{z}[q]\vert^2, \quad q=0,\ldots,p-1\\
&B_z[q_1,q_2] = \hat{z}[q_1]\hat{z}[q_2]\hat{z}[-q_1-q_2], \quad q_1,q_2=0,\ldots,p-1. \nonumber
\end{align}  
It is well known that the bispectrum determines a generic signal uniquely in a stable manner~\cite{bendory2017bispectrum}. 

In the heterogeneous model, it can be shown that in the limit of $N\to\infty$ the invariants of the observations converge to \TODO{should be written more accurately} 
\begin{align} \label{eq:mix_invariants}
\mu_{y^d} &= \frac{1}{K}\sum_{i=1}^K \mu_{x_i}, \nonumber\\
P_{y^d} &= \frac{1}{K}\sum_{i=1}^K P_{x_i} + \sigma^2L\mathbf{1}, \\
B_{y^d} &= \frac{1}{K}\sum_{i=1}^K (B_{x_i} +\mu_{x_i}\sigma^2L^2 A ), \nonumber
\end{align}
where $\mathbf{1}\in\mathbb{R}^L$ is a vector of ones, and $A\in\mathbb{R}^{L\times L}$ is a zero matrix except $A[0,0]=3$ and $A[i,0]=A[0,i]=A[i,i]=1$ for $i=1,\ldots,L-1$.
Given $\sigma^2$, one can remove the bias factors easily. 
We first discuss how to recover the signal $x_1,\ldots,x_k$ from~\eqref{eq:mix_invariants} up to symmetries, and later discuss how to avoid these symmetries. 

Recovering the set of $K$ signals from the invariants~\eqref{eq:mix_invariants} was studied~\cite{bandeira2017estimation}. In this work, it was shown that $K$ generic signals can be recovered from~\eqref{eq:mix_invariants}, up to permutation and cyclic shifts, as long as $K<\mathcal{P}(L)$ where
\begin{equation} \label{eq:Pl}
\mathcal{P}(L) := \frac{L+3+\left\lfloor L/2\right\rfloor +  \left\lceil (L-1)(L-2)/6\right\rceil}{L+1}.
\end{equation}
For $K\geq 5$, it suffices to require $K\leq \frac{L+5}{6}$. 
Since $\mathcal{P}(L) \approx L/6$, we conclude that the minimal number of samples scales as $\sqrt{6B}$. In other words, from $L$ samples, one can get order of $L^2$ frequencies. 
This bound was proved (by computational tools) for $K\leq 15$, and was conjectured in Conjecture 5.4 to hold true for any $K$~\cite{bandeira2017estimation}. \TODO{To stress the difference between identify the signals, and recover them.}

We introduce the set of signals \TODO{to explain where this set comes from}
\begin{equation}
\mathcal{S}(x_1,\ldots,x_K):=\left\{ \theta_0,\ldots,\theta_{K-1},\pi : R_{\theta_0}x_{\pi(0)}, \ldots,R_{\theta_{K-1}}x_{\pi(K-1)},
 \right\}
\end{equation}
for all cyclic shifts $R_{\theta_i}$ for $\theta_i=0,\ldots,L-1$, and a permutation $\pi$. Using this notation, we conclude the following result:
\begin{prop} \label{prop1}
Consider the  discrete periodic model~\eqref{eq:discrete_model} when $N\to\infty$. 
For $K\leq 15$ and  $\mathcal{P}(L)L>B$, one can identify the set of signals $\mathcal{S}(x_1,\ldots,x_K)$.
If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$.
\end{prop}	

It is important to note that Proposition~\eqref{prop1} is theoretical in the sense that it is not clear whether the bound~\eqref{eq:Pl} can be achieved computationally.  
This question was studied empirically in~\cite{boumal2018heterogeneous}. Numerical evidences suggest that the maximal number of signals that can recovered, up cyclic shifts and permutation, from~\eqref{eq:mix_bispectra} is $\sqrt{L}$. 
Strong theoretical support was provided in~\cite{weinthesis}. In particular,  it was proven that $K$ signals whose entries i.i.d.\ Gaussians can be recovered with high probability from their mixed bispectrum as long as $k\leq \sqrt{L}/\text{polylog}(L)$.
In this case, the highest frequency that can be estimated scales as $B\leq L^{3/2}$ (up to possible log factors). 



Proposition~\ref{prop1} suggests that all entries of the underlying signal can be identified in the regime of~$\mathcal{P}(L)>K$. However, given all possible cyclic shifts and permutations, there are $(L^K)\cdot K!$ \TODO{check this number}  different ways to order the signals $x_1,\ldots,x_K$. Hence, to guarantee unique recovery of the signal, up to cyclic shift, one must impose some prior on the signal, such as smoothness. In the following proposition, proved in Appendix~\ref{sec:proof_bandlimit}, we show that such unique ordering is possible under rather mild conditions.

\begin{prop} \label{prop:bandlimit}
Suppose that $x$ is generic, and let 
\begin{equation} \label{eq:sub_signals}
x_i[\ell] = x[K\ell + i], \quad \ell=0,\ldots,L-1.
\end{equation}
In addition, suppose that $\hx[m]=x_m$ for some $m$ and $x_m$.
Then, there exists only signal in $\mathcal{S}$, up to cyclic shift, obeying $\hx[m]=x_m$.
\end{prop}	

Our main interest is in bandlimited signals for which the spectrum vanishes starting from some frequency. Proposition~\ref{prop:bandlimit} implies that generically there exists at most one bandlimited signal in  $\mathcal{S}(x_1,\ldots,x_K)$ 
Hence, we conclude the following:
\begin{thm} \label{thm:discrete}
Consider the  discrete periodic model~\eqref{eq:discrete_model} when $N\to\infty$. Suppose that one entry of $\hx$ is known (e.g., $x$ is a bandlimited signal for which many of Fourier coefficients are zero). 
Then, For $K\leq 15$ and for $\mathcal{P}(B/K)>K$ (given in~\eqref{eq:Pl}), one can identify $x$ uniquely, up to shift. 
If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$.
\end{thm}

\subsection{Explicit expressions of the invariants} \label{sec:expressions}

We are now turning our attention to explicit computation of the moments as a function of the Fourier coefficients of $x$ (the high-resolution signal). This computation will serve to move from the discrete setting to the continuous one. To differ it from the  

We start by computing the mean, which is defined as the expected mean of the measurements: 
\begin{equation}
\begin{split}
M_1 = \E\left\{ \frac{1}{L} \sum_{\ell=0}^{L-1} y^d[\ell]\right\} =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y^d[\ell] =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1}
\sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{split}
\end{equation}
Since $\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I b \tau/B}=\delta_b$, we conclude that 
\begin{equation} \label{eq:mean}
\begin{split}
M_1 = \hx[0].
\end{split}
\end{equation}
This  implies, agreeing with~\eqref{eq:mix_bispectra} that the average over all measurements is just the mean of the signal.  

We can now proceed with the second moment:
\begin{equation} \label{eq:ps}
\begin{split}
M_2[n] &= \E\left\{\frac{1}{L}\sum_{\ell=0}^{L-1} y^d[\ell]y^d[\ell-n]\right\} =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y^d[\ell]y^d[\ell-n] \\ &=  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1}
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell}{L} + \frac{\tau}{B}\right)} \right)
\left(\sum_{b_2=-\tB}^{\tB}\overline{\hx}[b_2]e^{-2\pi\I b_2 \left(\frac{\ell-n}{L} + \frac{\tau}{B}\right)} \right) \\
&=
\sum_{b=-\tB}^{\tB}\vert \hat{x}[b]\vert ^2e^{2\pi\I bn/L}.
\end{split}
\end{equation}
Taking the $L$-points DFT of $M_2$ we get 
\begin{equation}
\begin{split}
P[q] &= \sum_{n=0}^{L-1}M_2[n]e^{-2\pi\I nq/L} = \sum_{b=-\tB}^{\tB}\vert \hat{x}[b]\vert^2\sum_{n=0}^{L-1}e^{-2\pi\I n(q-b)/L}.
\end{split}
\end{equation}
The last term is not zero if and only if $b = q + pL$ for some $p\in\mathbb{Z}$.  Hence, we conclude that the observed power spectrum is a mix of power spectra:
\begin{equation}
\begin{split}
\frac{1}{L}\hat{M}_2[q] &=  \sum_{p=0}^{K-1} \vert \hat{x}[(q+PL)\bmod L]\vert^2.
\end{split}
\end{equation}

The more interesting computation is of the bispectrum.
 The third-order autocorrelation is given by 
\begin{equation} \label{eq:3rd_moments}
\begin{split}
M_3[n_1,n_2] &= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y_\tau[\ell] y_\tau[\ell-n_1] y_\tau[\ell-n_2]\\ 
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} x\left(\frac{\ell}{L} + \frac{\tau}{B}\right) x\left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right)
x\left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right)\\
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }\right). 
\end{split}
\end{equation}
By changing the order of the summations, and noting that 
\begin{equation} \label{eq:delta}
\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I\tau (b_1+b_2+b_3)/B} = \delta_{b_1+b_2+b_3\bmod B},
\end{equation}
we get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] = 
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (b_1n_1 + b_2n_2)/L}.
\end{split}
\end{equation}
This expression can be understood in the Fourier domain by taking the $L\times L$ points DFT: 
\begin{equation} \label{eq:mix_bispectra}
\begin{split}
B[q_1,q_2] &= \sum_{n_1=0}^{L-1} \sum_{n_2=0}^{L-1}
M_3[n_1,n_2]e^{-2\pi\I(n_1q_1+n_2q_2)/L} \\ &=  
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (n_1(b_1+q_1) + n_2(b_2+q_2))} \\ & = \sum_{p_1=0}^{K-1} \sum_{p_2=0}^{K-1} \hat{x}[(q_1 + p_1L)\bmod L] \hat{x}[(q_2 + p_2L)\bmod L]\hat{x}[(-q_1-q_2 - (p_1+p_2)L)\bmod L].
\end{split}
\end{equation}
\begin{cor}
	If $K\leq 15$ and $\mathcal{P}(B/K)>K$, then the set of signals $\mathcal{S}(x_1,\ldots,x_K)$ are determined uniquely from~\eqref{eq:mean},\eqref{eq:ps} and~\eqref{eq:mix_bispectra}. 
	If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$. 
\end{cor}

\subsection{The continuous model} \label{sec:analysis_continuous}

Next, we examine the discrete model while letting $\theta$ to rotate on a finer sampling grid, while fixing the sampling grid $\mathcal{L}_0$ and the signal's bandwidth.  

Let $p$ denotes the over-sampling factor of the sampling grid of $\theta$. Similarly to~\eqref{eq:3rd_moments}, we can calculate  the third-order autocorrelation to be
\begin{equation}
\begin{split}
M_3[n_1,n_2] 
&= \frac{1}{LBp}\sum_{\tau=0}^{pB-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{pB}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{pB}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{pB}\right) }\right). 
\end{split}
\end{equation}
Similarly to~\eqref{eq:delta}, we have
\begin{equation} \label{eq:delta2}
\frac{1}{pB}\sum_{\tau=0}^{pB-1}e^{2\pi\I\tau (b_1+b_2+b_3)/pB} = \delta_{b_1+b_2+b_3\bmod pB},
\end{equation}
and hence we get the constraint $$b_3=(-b_1-b_2)\bmod pB=-b_1-b_2,$$
where the last equality follows from the range of $b_1,b_2$.
Hence, we directly get 
\begin{equation} \label{eq:3rd_moment_zeros}
\begin{split}
M_3[n_1,n_2] = 
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[-b_1-b_2]e^{-2\pi\I (b_1n_1 + b_2n_2)/L},
\end{split}
\end{equation}
and 
\begin{equation} \label{eq:mixed_bispectra_zeros}
\begin{split}
B[q_1,q_2] &= \sum_{n_1=0}^{L-1} \sum_{n_2=0}^{L-1}
M_3[n_1,n_2]e^{-2\pi\I(n_1q_1+n_2q_2)/L} \\ &=   \sum_{p_1=0}^{K-1} \sum_{p_2=0}^{K-1} \hat{x}[(q_1 + p_1L)\bmod L] \hat{x}[(q_2 + p_2L)\bmod L]\hat{x}[-q_1-q_2 - (p_1+p_2)L].
\end{split}
\end{equation}

This implies that we get the same bispectrum as in~\eqref{eq:mix_bispectra}, without the wrapped-around of the frequencies. 
That is, the bispectrum remains the same for any entry $\vert b_1 + b_2\vert \leq B$. For all other entries, the expression~\eqref{eq:mixed_bispectra_zeros} is zero, whereas~\eqref{eq:mix_bispectra} is generally not. 
This is true for any $p\geq 2$. 
This follows the intuition that if the signal is band-limited, then the taking more and more samples does not make a difference. \TODO{Does it?} 
In particular, it holds true for $p\to\infty$---that is, when $\theta$ is rotated continuously on the circle. In this case, the discrete model converges to the continuous model, which is the main interest of this paper. In appendix~\ref{sec:continuous_bispectrum} we derive expression~\eqref{eq:mixed_bispectra_zeros} directly in the continuum, without first considering the discrete case. 

Unfortunately, the results from~\cite{bandeira2017estimation} for bispectrum demixing assume a generic, periodic, signals. Thus, the expression of~\eqref{eq:mixed_bispectra_zeros} does not fall into this category and Proposition~\ref{prop1} does not hold. Yet, in many cases the aperiodic is provably easier than the periodic case since entries from other sides of the signal (e.g.,
low and high frequencies) do not mixed up. 
For instance, it is well know that a generic two-dimensional signal can be determined uniquely from its aperiodic autocorrelation but not from its periodic autocorrelation; see for example~\cite{hayes1982reconstruction}.\footnote{In practice, the mapping between the aperiodic autocorrelation and a signal might be extremely sensitive~\cite{barnett2018geometry}.}. The aperiodicity also plays a key role in other related fields, such as ultra-short pulse characterization~\cite{bendory2018signal}. 
Based on that intuition, we conjecture that the same super-resolution factor remains true for the continuous case, possibly with a different constant. 

\begin{conj} \label{conj:continuous}
Consider the  continuous periodic model~\eqref{eq:continuous_measurements} when $N\to\infty$, and that $x$ is a B-bandlimited signal, the  one can identify $x$ up to shift as long as $K\leq C \sqrt{B}$, for some constant $C$.
\end{conj}

\section{An expectation-maximization algorithm for super-resolution}

Our theoretical study is based on the invariant features. Conceptually, it suggests a two stages procedure: it starts with estimation of the set $\mathcal{S}(x_1,\ldots,x_K)$, and then identify one unique signal according to some prior (e.g., smoothness, bandlimit).
While efficient bispectrum demixing is possible in some regime~\cite{boumal2018heterogeneous,weinthesis}, this approach suffers from two drawbacks. First, it is not clear how to find a unique signal from $\mathcal{S}(x_1,\ldots,x_K)$ that agrees with the prior.  Second, any error in finding the appropriate set of rotations and permutation may result in a  completely different signal. Hence, such a procedure may be very sensitive to errors. 
As an alternative, we propose using the expectation-maximization (EM) framework described below. 

EM is a popular  framework to compute the marginalized maximum likelihood estimator (MMLE), proposed in~\cite{dempster1977maximum}. While it lacks rigorous theory, it works quite well in many cases. Hereafter, we assume here that $\theta$ is restricted to rotate on a discrete grid $\mathcal{T}$. For the sake of generality, we formulate the EM for a general linear operator $T$, not necessarily a sampling matrix.

\TODO{To write here the explicit model with a general linear transformation}
Given a set of $N$ measurements $y_1,\ldots,y_N$, the likelihood function  is proportional to $p(y_1,\ldots,y_N|x)p(x)$, where $p(x)$ is a prior on the signal. 
In this work, we suppose that the signal is Gaussian with zero mean and known covariance $\Sigma$.
Hence,  a simple calculation shows that the log-likelihood  then takes the form (up to a constant, cf.~\cite{bendory2017bispectrum,abbe2018multireference})
\begin{equation}
\log \mathcal{L}(y|x)  = -\frac{1}{2\sigma^2}\sum_{i=1}^{N}\|y_i - TR_{\theta_i}x\| - \frac{1}{2}x^T\Sigma^{-1}x.
\end{equation}
The algorithm aims to compute the MMLE by marginalizing over the the cyclic shifts, that is,  $\log \mathcal{L}(y|x)  = \sum_{\theta\in\mathcal{T}}\log \mathcal{L}(y|\theta,x)$. Computing the MMLE directly is intractable as one needs to evaluate the log likelihood at  an exponential number of combinations of rotations. The EM suggests to try to obtain the MMLE iteratively. 


Each EM iteration consists of two steps.
The first, called the E-step, computes the expected value of the likelihood function  given the current estimate of the signal $x_t$ and the data $y_1,\ldots,y_N$
\begin{equation}
\begin{split}
Q(x|x_t) &= \E_{\theta|y_1,\ldots,y_N,x_t}\left\{\ \log \mathcal{L}(y_1,\ldots,y_N,\theta|x_t).   \right\} \\
& = -\frac{1}{2\sigma^2}\sum_{i=1}^{N}\sum_{\tau\in\mathcal{T}}w_{i,\tau}\|y_i - TR_{\tau}x\| - \frac{1}{2}x^T\Sigma^{-1}x,
\end{split}
\end{equation} 
where 
\begin{equation} \label{eq:em_weights}
w_{i,\tau} = P[\theta_i = \tau] = \frac{e^{\frac{-1}{2\sigma^2}\|y_i-TR_\tau x_t\|^2 }}{\sum_{\tau\in\mathcal{T}}e^{\frac{-1}{2\sigma^2}\|y_i-TR_\tau x_t\|^2 }}.
\end{equation}
Then,  the second step is to maximize $Q$ with respect to $x$. In that case, the solution is obtained by solving the linear system of equations
\begin{equation} \label{eq:em_linear_system}
Ax = b,
\end{equation}
where 
\begin{align}
A :=&  \Sigma^{-1} + \frac{1}{\sigma^2}\sum_{i,\tau}\omega_{i,\tau} (R_\tau^{-1}T^TTR_\tau),\\ 
b :=&   \frac{1}{\sigma^2} \sum_{i,\tau}\omega_{i,\tau}R_\tau^{-1}T^Ty_i.
\end{align}
The EM is then iterate between computing the weights~\eqref{eq:em_weights} and solving the linear system~\eqref{eq:em_linear_system}. 

\begin{algorithm}
	\caption{Put your caption here}
	\begin{algorithmic}[1]
		
		\Procedure{Roy}{$a,b$}       \Comment{This is a test}
		\State System Initialization
		\State Read the value 
		\If{$condition = True$}
		\State Do this
		\If{$Condition \geq 1$}
		\State Do that
		\ElsIf{$Condition \neq 5$}
		\State Do another
		\State Do that as well
		\Else
		\State Do otherwise
		\EndIf
		\EndIf
		
		\While{$something \not= 0$}  \Comment{put some comments here}
		\State $var1 \leftarrow var2$  \Comment{another comment}
		\State $var3 \leftarrow var4$
		\EndWhile  \label{roy's loop}
		\EndProcedure
		
	\end{algorithmic}
\end{algorithm}


All expressions in this section were formulated for general linear operator $T$. When the linear operator is the sampling operator, both steps can be implemented efficiently using FFT. In the following section we present numerical results based on the efficient implementation. 

\section{Numerical results}


\section{Discussion} \label{sec:future_work}


In this work we studied the possibility for super-resolution using the bispectrum. In general, one can use higher moments. However, computing higher moments amplifies the noise; asymptotically, one need the number of measurements to scale like $\sigma^{2d}$ to compute the $d$th moment. On the other hand, computing higher moments provides more equations. For instance, in the discrete model, we have shown that the key step in the analysis is the reduction of the problem to heterogeneous MRA model~\eqref{eq:heter_mra}.  By taking the $d$th moment we will get  $O(L^{d-1})$ equations, and therefore we expect to be able to recover $O(L^{d-2})$ (up to symmetries). According to this line of reasoning, we conjecture that the maximal frequency would scales like $L^{d-1}$. The price would be the amplification of the noise, that is, one would need to acquire many additional measurements.  

The model considered in this paper can be naturally generalized to 
\begin{equation} \label{eq:general_model}
y = P (g\cdot x) + \varepsilon,\quad g\in G,
\end{equation}
where $g$ is a uniformly distributed random element of a compact group $G$ acting on $x$ by $(g\cdot x)(t) = x(g^{-1}t)$, where $x$ lies in some signal space, and $P$ is a linear operator.  In this manuscript we considered the group of cyclic shifts $\mathbb{Z}_L$ and 2-D rotations $SO(2)$, while $P$ was an equally-spaced sampling operator. The signal was assumed to lie in the space of bandlimited signals. 

In the cryo-EM case, $g\in SO(3)$ and the Fourier transform of $x$ is assumed to be bounded in a ball (``bandlimited'' volume). The linear operator $P$ would be an equally-spaced sampling of the tomographic projection of $g\cdot x$ from a fixed direction. The question then would be whether it is possible to reconstruct the 3-D structure to resolution beyond the resolution dedicated by the sampling operator---beyond the resolution of the 2-D images. Recent evidences suggest it is possible~\cite{chen2018single}. In addition, since the distribution over $SO(3)$ is usually non-uniform, it would be interesting to study the effect of the distribution on the maximal resolution that can be obtained. Another generalization of the model would be to allow other type of noise statistics. This might be important to X-ray free electron laser (XFEL), in which the data is corrupted with Poisson noise.
 
	
\bibliographystyle{plain}
\bibliography{ref}


\appendix

\section{Proof of Proposition~\ref{prop:bandlimit}} \label{sec:proof_bandlimit}
Suppose that $x_1,\ldots,x_K\in\R^L$ are known.
The combined signal is then given by 
\begin{equation}
x = \sum_{i=1}^K T_kZR_kx_k,
\end{equation}
where $R_k$ are (unknown) cyclic shifts of the signals $x_k$, $Z$ denotes a zero-padding operator (by a factor of $K$) so that $Zx_k\in\mathbb{R}^B$, and $T_k$ shifts the zero-padded signals by $k$ entries for $k=0,\ldots, K-1$. 
For instance, for $K=3$ we have: 
\begin{equation}
Zx = (x[0],0,0,x[1],0,0,x[2],...)\in\mathbb{R}^B.
\end{equation}

The Fourier transform of a signal $u\in\mathbb{R}^{L}$ is defined by 
\begin{equation}
\hat{u}[m]=\sum_{\ell=0}^{L-1}u[\ell]e^{-2\pi\I m\ell /L}, \quad m=0,\ldots,L-1. 
\end{equation}
The Fourier transform of $Zu$ is then given by 
\begin{equation}
\widehat{(Zu)}[m] = \sum_{\ell=0}^{L-1}u[\ell]e^{-2\pi\I m\ell /(B/K)}, \quad m=0,\ldots,B-1.
\end{equation}
In other words, $\widehat{(Zu)}[m] = \hat{u}[m\bmod L]$.


The Fourier transform of $ZR_{r_k}u$ is  given by 
\begin{equation}
\widehat{(ZR_{r_k}u)}[m] = e^{-2\pi\I m r_k L} \hat{u}[m\bmod L], \quad m=0,\ldots,B-1.
\end{equation}
This signal is shifted once again and we get
\begin{eqnarray} \label{eq:Fourier_structure}
\hat{x}[m] = \sum_{k=1}^K e^{-2\pi\I m( p_k+r_k K)/B} \hat{x}_k[m \bmod L]. 
\end{eqnarray}
for $m=0,\ldots,B-1$, 
where $r_k$ is a chosen randomly uniformly over $\{0,\ldots,L-1\}$, independently for each $k$, and $p_k$ represents the permutations, that is, $p_k\in\{0,\ldots K-1\}$, $p_k\neq p_\ell$ for all $k\neq \ell$ (note that we do have the freedom to fix one signal and its shift). 

Let us denote the set of rotations and permutation that satisfy the assumption  $\hx[m]=x_m$ by $\tilde{p}_k,\tilde{r}_k$. Let $E_k:=e^{-2\pi\I m( p_k+r_k K)/B}$, $\tilde{E}_k:=e^{-2\pi\I m( \tilde{p}_k+\tilde{r}_k K)/B}$ and $\hx_k:=\hat{x}_k[m \bmod L]$ for fixed $m$. Now, let us assume that there exists another $E_k$ that satisfies the constraint. In this case,
\begin{equation} \label{eq:inner_product}
x_m=\left\langle E_k,\hx_k\right\rangle = \left\langle \tilde{E}_k,\hx_k\right\rangle \quad \Rightarrow \quad\left\langle \tilde{E}_k -{E}_k,\hx_k\right\rangle =0.
\end{equation} 
For generic $x$, the orthogonal complement of $\hx_k$ is Lebesgue measure zero and therefore~\eqref{eq:inner_product} is not satisfied generically.  

\section{Derivation of the bispectrum in the continuous model} \label{sec:continuous_bispectrum}

In this appendix, we compute the bispectrum explicitly for the continuous setting. The third-order autocorrelation is given by (by averaging over all shifts $\ell\in\mathcal{L}$, and all rotations on the circle)
\begin{equation}
\begin{split}
M_3[n_1,n_2] &= \E_{\theta\sim\text{U}[0,1)}\left\{ \sum_{\ell=0}^{L-1}  y_\theta[\ell] y_\theta[\ell-n_1] y_\theta[\ell-n_2]\right\} 
\\&=\int_{0}^{1}\left(\frac{1}{L}\sum_{\ell=0}^{L-1} y_\theta[\ell] y_\theta[\ell-n_1] y_\theta[\ell-n_2]\right)d\theta\\ 
&= \frac{1}{L}\sum_{\ell=0}^{L-1}\int_{0}^{1} x\left(\frac{\ell}{L} + \theta\right) x\left(\frac{\ell-n_1}{L} + \theta\right)
x\left(\frac{\ell-n_2}{L} + \theta\right)d\theta\\
&= \frac{1}{L}\sum_{\ell=0}^{L-1}\int_{0}^{1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \theta\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \theta\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \theta\right) }\right). 
\end{split}
\end{equation}
Since $\int_{0}^{1}e^{2\pi\I\theta(b_1+b_2+b_3)}d\theta=\delta_{b_1+b_2+b_3}$, we get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] =   \sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB} \hat{x}[b_1]\hat{x}[b_2]\hat{x}[-b_1-b_2]e^{-2\pi\I (b_1n_1+b_2n_2)},
\end{split}
\end{equation}
which is exactly~\eqref{eq:3rd_moment_zeros}. Hence, taking the $L\times L$ DFT we get~\eqref{eq:mixed_bispectra_zeros}.

\end{document}

