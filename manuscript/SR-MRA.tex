\documentclass[english,12pt]{article}


\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\newcommand{\I}{\iota}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
%\newcommand{\tB}{\tilde{B}}
\newcommand{\tB}{B_w}
\newcommand{\hx}{\hat{x}}
\newcommand{\E}{\mathbb{E}}

\usepackage{color}
\newcommand{\TODO}[1]{{\color{red}{[#1]}}}


\newtheorem{mytheorem}{Theorem}
\numberwithin{equation}{section}
\numberwithin{mytheorem}{section} % important bit
\newtheorem{claim}[mytheorem]{Claim}
\newtheorem{conj}[mytheorem]{Conjecture}
\newtheorem{cor}[mytheorem]{Corollary}
\newtheorem{prop}[mytheorem]{Proposition}


\begin{document}

\title{Super-resolution meets multi-reference alignment}

\author{Tamir Bendory}
\date{January 2019}
\maketitle


\section{Introduction}

Discuss classical super-resolution, multi-reference alignment, bispectrum, the effect of noise and bias

\section{Model}

We assume to collect $N$ independent observations from the model 
\begin{equation} \label{eq:model}
y = PR_\theta x + \varepsilon,
\end{equation}
%so that 
%\begin{equation}
%y_i = PR_{\theta_i} x_i + \varepsilon_i, \quad i=1,\ldots,N.
%\end{equation}
where $x\in S^1$ is a signal on the circle, $R_\theta$ denotes a random, unknown rotation, and $\theta$ is distributed uniformly $\theta\sim \text{Uniform}[0,1)$. 
The noise is assumed to be normal i.i.d.\  $\varepsilon\sim\mathcal{N}(0,\sigma^2 I)$.
In this work, we mainly focus on the high noise regime in which $\sigma$ is greater than $\|x\|_2$. 
Following the rotation, the operator $P$ collects $L$ equally-spaced samples of the signal. Thus, the recorded samples of the $i$th measurement are given by 
\begin{equation}
y_i[\ell] = \left(R_{\theta_i} x\right)[\ell] + \varepsilon_i[\ell], \quad \ell=0,\ldots,L-1.
\end{equation}
Throughout, we assume that $\sigma^2$. In many applications, the variance of the noise can be estimated accurately from the samples, or is known apriori. %Specifically for~\eqref{eq:model} the variance can be estimated by

The underlying  signal  is assumed to be band-limited so it can be expanded in a finite Fourier expansion 
\begin{eqnarray} \label{eq:fourier_expansion}
x(t) = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I bt }. \quad t\in[0,1),
\end{eqnarray}
We are interested the interplay between the number of samples $L$ and the signal's band-width $B := 2\tB+1$. We denote this ratio by  $LK=B$ for some \emph{down-sampling factor} $K\in\mathbb{Z}_{>0}$.  
This model, for which we refer to as the \emph{continuous SR model}, is the main subject of this paper. 


In addition to the continuous case, we consider the \emph{discrete SR model}. 
In this model, we allow $\theta$ to rotate only on a grid over $S^1$ defined by  $$\mathcal{B}:=\left\{0,\frac{1}{B},\ldots\frac{B-1}{B}\right\}.$$
In each measurement, the signal is rotated uniformly over  $\mathcal{B}$, and then sampled on a coarser grid 
\begin{equation} \label{eq:grid_L}
\mathcal{L}_0:=\left\{0,\frac{K}{B},\frac{2K}{B},\ldots,\frac{(L-1)K}{B}\right\}.
\end{equation}

Under this model, the samples of the $i$th measurement can be then written as
\begin{equation}
y_i[\ell] = x\left(\frac{\ell K+\tau}{B}\right)=x\left(\frac{\ell}{L} + \frac{\tau}{B}\right), \quad \ell=0,\ldots L-1,
\end{equation}
for some random $\tau\in\{0,\ldots B-1\}$. 
We also note that according to~\eqref{eq:fourier_expansion},  $y$ can be expanded by a Fourier series as
\begin{eqnarray}
y_\tau[\ell] = \sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{eqnarray}

The discrete model can be formulate conveniently in a matrix-vector notation as  
\begin{equation} \label{eq:discrete_model}
y^d = P_BR_{\theta_\mathcal{B}} x^d + \varepsilon,
\end{equation}
where $x^d\in\mathbb{R}^{B}$ is the restriction of $x$ to $\mathcal{B}$, $R_{\theta_\mathcal{B}}$ is a circular shift (uniformly distributed) on $\mathcal{B} $and the sampling operator $P_B\in\mathbb{R}^{B\times B}$ can be thought of as a diagonal matrix, whose diagonal is composed of 1's every other $K$ entry, and zero otherwise

The main goal of this work is to analyze the conditions enabling accurate estimate of $x$ in the continuous and discrete models in high noise regimes. As we show, accurate recovery depends on the relations between two pairs of parameters: the number of measurements as a function of the noise level, and the number of required samples as a function of the signal's band-width. Since our analysis is based on the method of moments, the required number of measurements scales asymptotically as $\sigma^{2d}$, where $d$ is the higher-order moment used~\cite{abbe2018estimation,bandeira2017estimation}. 
In this work, we focus on the third-moment---the bispectrum---and thus $N$ should be, at least, proportional to $\sigma^6$. In Section XXX we discuss the implication of using higher moments. Hence, we now proceed to analyze the how many samples are required for a given band-width. 


\section{Analysis}

We begin by analyzing the discrete setting~\eqref{eq:discrete_model}. For the analysis, we split the discrete signal $x_B\in\mathbb{R}^B$ into $K$ signals, denoted by $x_0,\ldots,x_{K-1}\in\mathbb{R}^L$ as follows:
\begin{eqnarray}
x_i[\ell] = x^d[K\ell+i], \quad \ell=0,\ldots L-1. 
\end{eqnarray}
Each one of the signals corresponds to some random rotation of $x$ on the grid  $$\mathcal{L}_i:=\left\{i,\frac{K+i}{B},\frac{2K+i}{B},\ldots,\frac{(L-1)K+i}{B}\right\}.$$
Using this notation, one can reformulate the model as 
\begin{equation} \label{eq:heter_mra}
y^d =  R_{\theta_{\mathcal{L}_0}} x_{v} + \varepsilon,
\end{equation}
where $v$ distributed uniformly over $\{0,\ldots,K-1\}$ and $\mathcal{L}_0$ is defined in~\eqref{eq:grid_L}. 

The model~\eqref{eq:heter_mra} has been studied in the literature under the name \emph{heterogeneous multi-reference alignment}~\cite{perry2017sample,bandeira2017estimation,boumal2018heterogeneous}. In particular, in the limit of $N\to\infty$ it is straight-forward to show that 
\begin{align} \label{eq:mix_invariants}
\mu_{y^d} &= \frac{1}{K}\sum_{i=1}^K \mu_{x_i}, \nonumber\\
P_{y^d} &= \frac{1}{K}\sum_{i=1}^K P_{x_i} + \sigma^2L\mathbf{1}, \\
B_{y^d} &= \frac{1}{K}\sum_{i=1}^K (B_{x_i} +\mu_{x_i}\sigma^2L^2 A ), \nonumber
\end{align}
where $\mathbf{1}\in\mathbb{R}^L$ is a vector of ones, and $A\in\mathbb{R}^{L\times L}$ is a zero matrix except $A[0,0]=3$ and $A[i,0]=A[0,i]=A[i,i]=1$ for $i=1,\ldots,L-1$.
Given $\sigma^2$, one can debias the invariant estimations and the problem reduces to the question of demixing.

Recovering the set of $K$ signals from the invariants~\eqref{eq:mix_invariants} was studied~\cite{bandeira2017estimation}. In this work, it was shown that $K$ generic signals can be recovered from~\eqref{eq:mix_invariants}, up to permutation and cyclic shifts, as long as $K<\mathcal{P}(L)$ where
\begin{equation} \label{eq:Pl}
\mathcal{P}(L) := \frac{L+3+\left\lfloor L/2\right\rfloor +  \left\lceil (L-1)(L-2)/6\right\rceil}{L+1}.
\end{equation}
For $K\geq 5$, it suffices to require $K\leq \frac{L+5}{6}$. 
Since $\mathcal{P}(L) \approx L/6$, we conclude that the bound on the down-sampling factor scales as $\sqrt{B/6}$.
This bound was proved (by computational tools) for $K\leq 15$, and was conjectured to hold true for any $K$~\cite{bandeira2017estimation}.

Therefore, we conclude the following result:
\begin{prop} \label{prop1}
Consider the  discrete periodic model~\eqref{eq:discrete_model} when $N\to\infty$. 
For $K\leq 15$ and for $\mathcal{P}(B/K)>K$, one can identify the signals 
\begin{equation} \label{eq:set_signals}
R_{\theta_0}x_{\pi(0)}, \ldots,R_{\theta_{K-1}}x_{\pi(K-1)},
\end{equation}
for some arbitrary cyclic shifts $R_{\theta_i}$ for $i=0,\ldots,L-1$, and a permutation $\pi$.
If Conjecture 5.4 in~\cite{bandeira2017estimation} is valid, the it holds true also for $K>15$.
\end{prop}	

It is important to note that Proposition~\eqref{prop1} is theoretical in the sense that it is not clear whether the bound~\eqref{eq:Pl} can be achieved computationally.  
This question was studied empirically in~\cite{boumal2018heterogeneous}. Numerical evidences suggest that the maximal number of signals that can recovered, up cyclic shifts and permutation, from~\eqref{eq:mix_bispectra} is $\sqrt{L}$. If this is true, then the number of signals that can be computationally 
demixed is $K\leq \sqrt{L}$, or, $K\sim B^{1/3}$.  \TODO{Alex's thesis}.

Proposition~\ref{prop1} suggests that all entries of the underlying signal can be recovered in the regime of~\eqref{eq:Pl}. However, there are $(L^K)\cdot K!$ \TODO{check this number}  different ways to order the signals $x_1,\ldots,x_K$. Hence, to guarantee unique recovery of the signal one must impose some prior on the signal, such as smoothness. In the following... 

\begin{prop} \label{prop:bandlimit}
If $x$ is a generic bandlimited signal, then there is only one unique ordering of~\eqref{eq:set_signals} which obeys this bandlimit. 
\end{prop}	
\begin{proof}
	See Appendix XXX.
\end{proof}

\begin{conj} \label{conj1}
	Under the discrete-periodic signal, one can sub-sample by a factor of  	$K\leq \sqrt{B/6}$ and retrieve  $x$ on the grid $\mathcal{B}$, up to shift, under some smoothing condition. \textbf{We should prove this conjecture.}
\end{conj}	

We are now turning our attention to explicit computation of the moments as a function of the Fourier coefficients of $x$ (the high-resolution signal). This computation will serve to move from the discrete setting to the continuous one. To differ it from the  

We start by computing the mean, which is defined as the expected mean of the measurements: 
\begin{equation}
\begin{split}
M_1 = \E\left\{ \frac{1}{L} \sum_{\ell=0}^{L-1} y^d[\ell]\right\} =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y^d[\ell] =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1}
\sum_{b=-\tB}^{\tB}\hat{x}[b]e^{2\pi\I b \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }.
\end{split}
\end{equation}
Since $\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I b \tau/B}=\delta_b$, we conclude that 
\begin{equation} \label{eq:mean}
\begin{split}
M_1 = \hx[0].
\end{split}
\end{equation}
This  implies, agreeing with~\eqref{eq:mix_bispectra} that the average over all measurements is just the mean of the signal.  

We can now proceed with the second moment:
\begin{equation} \label{eq:ps}
\begin{split}
M_2[n] &= \E\left\{\frac{1}{L}\sum_{\ell=0}^{L-1} y^d[\ell]y^d[\ell-n]\right\} =  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y^d[\ell]y^d[\ell-n] \\ &=  \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1}
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell}{L} + \frac{\tau}{B}\right)} \right)
\left(\sum_{b_2=-\tB}^{\tB}\overline{\hx}[b_2]e^{-2\pi\I b_2 \left(\frac{\ell-n}{L} + \frac{\tau}{B}\right)} \right) \\
&=
\sum_{b=-\tB}^{\tB}\vert \hat{x}[b]\vert ^2e^{2\pi\I bn/L}.
\end{split}
\end{equation}
Taking the $L$-points DFT of $M_2$ we get 
\begin{equation}
\begin{split}
P[q] &= \sum_{n=0}^{L-1}M_2[n]e^{-2\pi\I nq/L} = \sum_{b=-\tB}^{\tB}\vert \hat{x}[b]\vert^2\sum_{n=0}^{L-1}e^{-2\pi\I n(q-b)/L}.
\end{split}
\end{equation}
The last term is not zero if and only if $b = q + pL$ for some $p\in\mathbb{Z}$.  Hence, we conclude that the observed power spectrum is a mix of power spectra:
\begin{equation}
\begin{split}
\frac{1}{L}\hat{M}_2[q] &=  \sum_{p=0}^{K-1} \vert \hat{x}[(q+PL)\bmod L]\vert^2.
\end{split}
\end{equation}

The more interesting computation is of the bispectrum.
 The third-order autocorrelation is given by 
\begin{equation}
\begin{split}
M_3[n_1,n_2] &= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} y_\tau[\ell] y_\tau[\ell-n_1] y_\tau[\ell-n_2]\\ 
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} x\left(\frac{\ell}{L} + \frac{\tau}{B}\right) x\left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right)
x\left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right)\\
&= \frac{1}{LB}\sum_{\tau=0}^{B-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{B}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{B}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{B}\right) }\right). 
\end{split}
\end{equation}
By changing the order of the summations, and noting that 
\begin{equation} \label{eq:sum}
\frac{1}{B}\sum_{\tau=0}^{B-1}e^{2\pi\I\tau (b_1+b_2+b_3)/B} = \delta_{b_1+b_2+b_3\bmod B},
\end{equation}
we get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] = 
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (b_1n_1 + b_2n_2)/L}.
\end{split}
\end{equation}
This expression can be understood in the Fourier domain by taking the $L\times L$ points DFT: 
\begin{equation} \label{eq:mix_bispectra}
\begin{split}
B[q_1,q_2] &= \sum_{n_1=0}^{L-1} \sum_{n_2=0}^{L-1}
M_3[n_1,n_2]e^{-2\pi\I(n_1q_1+n_2q_2)/L} \\ &=  
\sum_{b_1=-\tB}^{\tB}\sum_{b_2=-\tB}^{\tB}\hat{x}[b_1]\hat{x}[b_2]\hat{x}[(-b_1-b_2)\bmod B]e^{-2\pi\I (n_1(b_1+q_1) + n_2(b_2+q_2))} \\ & = \sum_{p_1=0}^{K-1} \sum_{p_2=0}^{K-1} \hat{x}[(q_1 + p_1L)\bmod L] \hat{x}[(q_2 + p_2L)\bmod L]\hat{x}[(-q_1-q_2 - (p_1+p_2)L)\bmod L].
\end{split}
\end{equation}
\begin{cor}
	By Proposition~\ref{prop1}, the set of signals~\eqref{eq:set_signals} are determined uniquely from~\eqref{eq:mean},\eqref{eq:ps} and~\eqref{eq:mix_bispectra}, as long as $\mathcal{P}(B/K)>K$. If Conjecture~\ref{conj1} is true, then it determines $x$ uniquely under some smoothness prior.  
\end{cor}

\section{Finer discretization and removing the periodicity in Fourier}

Now, we want to examine what happens when we replace $\mathcal{B}$ with a finer grid by some integer $p\geq 1$, while fixing the sampling grid $\mathcal{L}_0$. 
In this case, we can write  the third-order autocorrelation and get 
\begin{equation}
\begin{split}
M_3[n_1,n_2] 
&= \frac{1}{LBp}\sum_{\tau=0}^{pB-1}\sum_{\ell=0}^{L-1} 
\left(\sum_{b_1=-\tB}^{\tB}\hat{x}[b_1]e^{2\pi\I b_1 \left(\frac{\ell-n_1}{L} + \frac{\tau}{pB}\right) }\right) 
\left(\sum_{b_2=-\tB}^{\tB}\hat{x}[b_2]e^{2\pi\I b_2 \left(\frac{\ell-n_2}{L} + \frac{\tau}{pB}\right) } \right) \\
&\times \left(\sum_{b_3=-\tB}^{\tB}\hat{x}[b_3]e^{2\pi\I b_3 \left(\frac{\ell}{L} + \frac{\tau}{pB}\right) }\right). 
\end{split}
\end{equation}
Similarly to~\eqref{eq:mix_bispectra}, we have
\begin{equation} \label{eq:sum2}
\frac{1}{pB}\sum_{\tau=0}^{pB-1}e^{2\pi\I\tau (b_1+b_2+b_3)/pB} = \delta_{b_1+b_2+b_3\bmod pB},
\end{equation}
and hence we get the constraint $$b_3=(-b_1-b_2)\bmod pB=-b_1-b_2,$$
where the last equality follows from the range of $b_1,b_2$.
This implies that we get the same bispectrum as in~\eqref{eq:mix_bispectra}, without the wrapped-around of the frequencies. As long as we assume that the spectrum of $x$ is $B$-periodic, then we get exactly the same expression. 
In other words, even if we let $\theta$ to rotated on a fine grid (with an arbitrary over-sampling factor $p$), then the averaged bispectra remains unchanged.
This follows the intuition that if the signal is band-limited, then the taking more and more samples does not make a difference. 

What happens if we remove the periodicity assumption in the frequency domain? In this case, the bispectrum remains as in~\eqref{eq:mix_bispectra}, however, many of its entries will be zero (for all indices $\vert b_1+b_2\vert \geq \tB$). The results from Bandiera et al. do not hold anymore in this case. Yet, we can safely conjecture that the $\sqrt{B}$ factor remains true in this case (which is, in fact, easier).  


%\section{Back to the continuous setup}

By taking $p\to\infty$ we let the grid to rotate freely on the circle. Therefore, in the continuous setting we need to acquire $L\sim\sqrt{B}$ samples. Note also that indeed the expression~\eqref{eq:mix_bispectra} coincides with the expression we got in the continuous setting in a previous note.

\section{An expectation-maximization algorithm}

The method of moments approach is sensitive; EM takes everything into account.

\section{Future work}
general group actions

cryo-EM

higher moments

non-periodic signals 

	
	
\bibliographystyle{plain}
\bibliography{ref}


\appendix

\section{Proof of Proposition~\ref{prop:bandlimit}}
Suppose that $x_1,\ldots,x_K\in\R^L$ are known.
The combined signal is then given by 
\begin{equation}
x = \sum_{i=1}^K T_kZR_kx_k,
\end{equation}
where $R_k$ are (unknown) cyclic shifts of the signals $x_k$, $Z$ denotes a zero-padding operator (by a factor of $K$) so that $Zx_k\in\mathbb{R}^B$, and $T_k$ shifts the zero-padded signals by $k$ entries for $k=0,\ldots, K-1$. 
For instance, for $K=3$ we have: 
\begin{equation}
Zx = (x[0],0,0,x[1],0,0,x[2],...)\in\mathbb{R}^B.
\end{equation}

The Fourier transform of a signal $u\in\mathbb{R}^{L}$ is defined by 
\begin{equation}
\hat{u}[m]=\sum_{\ell=0}^{L-1}u[\ell]e^{-2\pi\I m\ell /L}, \quad m=0,\ldots,L-1. 
\end{equation}
The Fourier transform of $Zu$ is then given by 
\begin{equation}
\widehat{(Zu)}[m] = \sum_{\ell=0}^{L-1}u[\ell]e^{-2\pi\I m\ell /(B/K)}, \quad m=0,\ldots,B-1.
\end{equation}
In other words, $\widehat{(Zu)}[m] = \hat{u}[m\bmod L]$.


The Fourier transform of $ZR_{r_k}u$ is  given by 
\begin{equation}
\widehat{(ZR_{r_k}u)}[m] = e^{-2\pi\I m r_k L} \hat{u}[m\bmod L], \quad m=0,\ldots,B-1.
\end{equation}
for 
This signal is shifted once again and we get
\begin{eqnarray} \label{eq:Fourier_structure}
\hat{x}[m] = \sum_{k=1}^K e^{-2\pi\I m( p_k+r_k K)/B} \hat{x}_k[m \bmod L] := \sum_{k=1}^K E[m,k] \hat{x}_k[m \bmod L]
\end{eqnarray}
for $m=0,\ldots,B-1$, 
where $r_k$ is a chosen randomly uniformly over $\{0,\ldots,L-1\}$, independently for each $k$, and $p_k$ represents the permutations, that is, $p_k\in\{0,\ldots K-1\}$, $p_k\neq t_\ell$ for all $k\neq \ell$ (note that we do have the freedom to fix one signal and its shift). 

By assumption, there exists at least one entry for which
$\hx[m]=0$. We also note that for fixed $m$, all entries   
$E[m,k]$ are not equal to each other. 

% the system can be written in matrix-vector multiplication. In particular, we write 
%\begin{equation}
%\hat{x} = X_k E,
%\end{equation} 
%where $\hat{x}\in\C^B$, each column of the matrix $X_K\in\C^{B\times K}$ is $\hat{x}_k[m \bmod L]$, 
%and $E\in\C^{K}


\end{document}

